Ephraim, I guy I grew up with and have remained friends with, is incredibly smart. When he was still in college, he was working on ideas for synthetic skin that would make prosthetics more natural looking, and won some awards and research grants for the stuff he came up with. He did postdoc research for a while, but then got a job offer from a robotics company. 

  
  
I had never heard of this company, but it wasn’t your average startup, because there was a lot of money behind it. The job paid really well. When I met him for a drink after he accepted the offer, he suggested I might also be able to make some money helping the company with their promotional materials. He’s always thrown freelance writing gigs my way whenever he had a chance.  

  
  
Ephraim wasn’t just in it for money, however; he is a guy who has to be passionate about what he does. As he tried to sell me on the company he was obviously deeply excited about the challenge of getting over the Uncanny Valley and the ultimate benefits of convincingly human-looking robots. 

  
  
He talked about how the Japanese and Koreans were already using robots to help care for the elderly, but that more natural-looking androids, made of “soft, stretchy, fluid stuff, like us,” would be both more comforting and safer to be around. 

  
  
I knew Ephraim’s research had involved a sort of biosynthesis that involved growing keratin-producing cells in a collagen base, so that the skin not only looked like real skin but felt like it. His robots would be huggable.

  
  
“Is that the market, then?” I asked. “Nursing homes?” I knew enough to guess that these things would cost well into six figures, and wondered how that would be more economical than human labor.

  
  
He showed me some of the marketing stuff, and they really did need some help with the writing. It was along the lines of, “Kind for sick/elder! Help customer with happiness! Entertainment purposes!”

  
  
“Something tells me ‘Entertainment purposes’ is where the money is,” I said. 

  
  
“Well, people need entertainment,” he said, laughing. As we were both getting a little drunk by that point, we degenerated into hilarity about the entertainment purposes of soft-skinned robots. 

  
  
The next time we met, he had already started drinking without me, and he seemed a lot less optimistic. Something was bothering him. After a little small talk, he got down to it. 

  
  
“The challenge of the biologically-based materials is that they need water and nutrients, just like living tissue,” he said. “So what I was working on when they hired me was a sort of circulatory system, a network of capillaries under the skin to deliver thermal hydrogels. It’s been a difficult thing to get right, but I knew with enough tinkering I could make it work.  And now I have. It’s in prototype.”

  
  
He stopped talking, and I waited, wondering what he was so reluctant to say.

  
  
“The gel they’ve produced,” he finally said. “It’s dyed red.”

  
  
I didn’t know what to think. I sat there turning over the implications.

  
  
“The AI these robots use is very basic,” he said slowly. “No one is pretending there’s any consciousness there. Their humanness, their…aliveness, it’s all appearance. But the appearance, oh my God. They have dozens of tiny servos in the face alone. Their expressions are unbelievable. They can show a full range of emotions. Including pain.”

  
  
“And they can bleed,” I said. 

  
  
“There’s no reason for the gel to be red,” he said. “No one should ever see it.”

  
  
“Unless the user wants to cut them.”

  
  
We were silent for a moment. Then he started trying to talk himself back into believing in the project.

  
  
“Awful though it may be, there are poor, broken dregs who feel the need to do that sort of thing. Maybe if they have some sort of outlet it would help keep them away from real people.”

  
  
I tried to consider it from this utilitarian point of view. It might have merit, I thought. “But it might also just encourage the poor, broken dregs,” I said. “They know the robot can’t really feel pain, so the partial satisfaction they got from it might just sharpen their hunger for the real thing.”

  
  
He looked thoughtful. “You know, I remember seeing in the company budget that some kind of psychological research is being funded. I bet that’s what it’s about. Poor, broken dregs: more or less likely to do real harm? I’d really like to know what they’ve found.” 

  
  
That was the last time I talked to him. But about a week later, I got an email with some .pdf attachments that turned out to be copies of the psych studies Ephraim had somehow gotten his hands on. I was confused at first because they were not what we had thought. 

  
  
They did not reference pleasure or excitement from inflicting pain. They were measuring the opposite reaction, the empathetic revulsion ordinary people exhibited at seeing video footage of the humanoids being cut and mutilated. 

  
  
The findings were difficult to parse, but seemed to indicate that the right preparation, including “educating the subjects before watching the videos about the artifice involved,” and “emphasizing the fallacy of anthropomorphism,” could help create a “top-down suppression” of the hormonal empathy reaction the videos triggered in unprepared subjects. There was some discussion of future avenues of research involving getting subjects to actively participate in mutilating the robots.

  
  
I don’t know what to think about this, and I haven’t been able to contact Ephraim. The last word I have from him is the message included with the copies of the studies: 

  
  
“Were so dumb. They arent for the poor broken dregs. They are going to finish the job of breaking the rest of us.”  
